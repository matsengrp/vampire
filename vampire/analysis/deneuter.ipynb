{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analysis of data from:\n",
    "\n",
    "De Neuter, N., Bartholomeus, E., Elias, G., Keersmaekers, N., Suls, A., Jansens, H., … Ogunjimi, B. (2018). Memory CD4 + T cell receptor repertoire data mining as a tool for identifying cytomegalovirus serostatus. Genes & Immunity, 1. <https://doi.org/10.1038/s41435-018-0035-y>\n",
    "\n",
    "Here's their description of the data:\n",
    "\n",
    "> In this study, we collected peripheral blood samples from 9\n",
    "CMV seropositive and 24 CMV seronegative healthy Belgian\n",
    "adults. We sequenced TCRβ sequences from the CD4\n",
    "+CD45RO+ lymphocyte population only, as opposed to the\n",
    "CD4+CD45RO+/− and CD8+CD45RO+/- lymphocyte\n",
    "populations collected in the original study [15], and thus\n",
    "focused solely on the immune signal within the CD4+\n",
    "memory repertoire. After removal of out of frame TCR\n",
    "sequences, 2,204,828 distinct TCRβ sequences were\n",
    "obtained, with a mean of 66 813 sequences per individual.\n",
    "\n",
    "I took these 33 repertoires and randomly split them into 22 training sets and then 11 testing sets. \n",
    "The training sets were mixed and 10% used for actual training, with 90% available for validation.\n",
    "\n",
    "(Note that the original data set has a few replicate samples from some of the repertoires, but I only selected one of the two replicates)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "suppressMessages(library(cowplot))\n",
    "library(jsonlite)\n",
    "library(tools)\n",
    "suppressMessages(library(pROC))\n",
    "library(devtools)\n",
    "suppressMessages(devtools::load_all('../R/sumrep'))\n",
    "source('../R/plot.R')\n",
    "\n",
    "theme_set(theme_minimal())\n",
    "source_colors = c(basic = \"#fc8d62\", count_match = \"#66c2a5\", olga =\"#8da0cb\", data = \"#A3A3A3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '../_ignore/plotting/2019-01-01-deneuter/'\n",
    "data_path = function(path) paste0(data_dir, path)\n",
    "json_path = data_path('../deneuter-2018-12-31.json')\n",
    "train_dir = data_path('deneuter-2018-12-31.train/')\n",
    "extras_path = data_path('../2019-01-01-deneuter-extras.csv')\n",
    "\n",
    "test_samples = lapply(\n",
    "    fromJSON(json_path)$test_paths,\n",
    "    function(path) tools::file_path_sans_ext(basename(path)))\n",
    "\n",
    "output_dir = '_output_deneuter/'\n",
    "system(paste('mkdir -p ', output_dir))\n",
    "output_path = function(path) paste0(output_dir, path)\n",
    "# This notebook makes nice versions of plots in this directory:\n",
    "normalizePath(output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following command should run if the data is in the right place."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summarized = data_path('summarized.agg.csv')\n",
    "system(paste('ls', summarized), intern=TRUE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "We will be comparing the VAE methods to OLGA + the thymic Q multiplier suggested by Thierry. \n",
    "For simplicity we will be referring to this method as \"OLGA\". \n",
    "\n",
    "We can't compare likelihoods between OLGA and the VAE, because OLGA happily assigns zero probability to quite a few of the observed sequences in the test set. \n",
    "If we take this literally, this means that OLGA has zero out of sample likelihoods for this test set. \n",
    "For example, here we see that it assigns zero probability to 13 of 500 sequences from the first test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system(\n",
    "    paste(\"grep '\\t0.0'\", data_path('H10_B0/test-head.pgen.tsv'), '| wc -l'), \n",
    "    intern=TRUE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Here we set the regularization parameter beta.\n",
    "0.75 looks like the best from staring at the Seshadri results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "our_beta = 0.75\n",
    "fit_dir = paste0(train_dir, our_beta, '/')\n",
    "fit_path = function(path) paste0(fit_dir, path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Let's compare the CDR3 length distribution between the various programs and the data sets. \n",
    "The programs will appear with thick colored lines, while the thin gray lines represent the test data sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prep_sumrep = function(path) {\n",
    "    df = read.csv(path, stringsAsFactors=FALSE)\n",
    "    colnames(df)[colnames(df) == 'amino_acid'] = 'junction_aa'\n",
    "    data.table(df)\n",
    "}\n",
    "named_summary = function(summary_fun, summary_name, path, data_source, data_group) {\n",
    "    df = data.frame(summary_fun(path))\n",
    "    colnames(df) = c(summary_name)\n",
    "    df$source = data_source\n",
    "    df$group = data_group\n",
    "    df\n",
    "}\n",
    "prep_summaries_general = function(data_paths, olga_str, basic_str, count_match_str, summary_fun, summary_name) {\n",
    "    aux = function(path, data_source, data_group) {\n",
    "        named_summary(summary_fun, summary_name, path, data_source, data_group)\n",
    "    }\n",
    "    data_df = do.call(rbind, \n",
    "                 lapply(\n",
    "                     data_paths,\n",
    "                     function(path) aux(path, 'data', path)\n",
    "                 ))\n",
    "    df = rbind(\n",
    "        aux(fit_path(olga_str), 'olga', 'olga'),\n",
    "        aux(fit_path(basic_str), 'basic', 'basic'),\n",
    "        aux(fit_path(count_match_str), 'count_match', 'count_match') \n",
    "    )\n",
    "    df = rbind(df, data_df)\n",
    "    df$size = 1-as.numeric(df$source == 'data')\n",
    "    df\n",
    "}\n",
    "prep_summaries = function(summary_fun, summary_name) {\n",
    "    test_head_csvs = \n",
    "        lapply(test_samples, function(sample) data_path(paste0(sample, '/', sample, '.for-test.head.csv')))\n",
    "    prep_summaries_general(test_head_csvs, 'olga-generated.csv', 'basic/vae-generated.csv', \n",
    "                           'count_match/vae-generated.csv', summary_fun, summary_name)\n",
    "}\n",
    "plot_summaries = function(df, summary_name, binwidth=1) {\n",
    "    theme_set(theme_minimal(base_size=18))\n",
    "    p = ggplot(df,\n",
    "        aes_string(summary_name, color='source', group='group', size='size')) + \n",
    "        geom_freqpoly(aes(y=..density..), binwidth=binwidth) + \n",
    "        scale_size(range=c(0.2, 1.2), guide='none') +\n",
    "        theme(legend.justification=c(0,1), legend.position=c(0,1)) +\n",
    "        scale_color_manual(values=source_colors)\n",
    "\n",
    "    ggsave(output_path(paste0(summary_name, '.png')), width=8, height=4.5)\n",
    "    p\n",
    "}\n",
    "\n",
    "plot_summaries(prep_summaries(\n",
    "    function(path) getCDR3LengthDistribution(prep_sumrep(path), by_amino_acid = TRUE), \n",
    "    'CDR3_length'), 'CDR3_length')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each CDR3 sequence, let's look at the distance to the nearest neighbor CDR3 sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_summaries(prep_summaries(\n",
    "    function(path) getNearestNeighborDistribution(prep_sumrep(path), column='junction_aa', approximate=FALSE),\n",
    "    'nearest_neighbor_distance'), \n",
    "'nearest_neighbor_distance')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's explore the distribution of pairwise distances between the CDR3 sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_summaries(prep_summaries(\n",
    "    function(path) getPairwiseDistanceDistribution(prep_sumrep(path), column='junction_aa', approximate=FALSE),\n",
    "    'pairwise_distance'), \n",
    "'pairwise_distance')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at divergences from the test sets for TCR sequences generated by the various programs.\n",
    "Each data point in these boxplots is a divergence between the simulated set of sequences and a collection of sequences from the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = read.csv(summarized)\n",
    "\n",
    "facet_labeller = function(s) {\n",
    "    s = sub(\"sumdiv_\",\"\",s)\n",
    "    s = gsub(\"_\",\" \",s)\n",
    "    s = sub(\"distance\",\"dist\",s)\n",
    "    s\n",
    "}\n",
    "\n",
    "compare_model_divergences = function(df, beta) {\n",
    "    df = df[df$beta == beta,]\n",
    "    id_vars = c('test_set', 'model')\n",
    "    measure_vars = grep('sumdiv_', colnames(df), value=TRUE)\n",
    "    df = df[c(id_vars, measure_vars)]\n",
    "    theme_set(theme_minimal())\n",
    "    ggplot(\n",
    "        melt(df, id_vars, measure_vars, variable.name='divergence_name', value.name='divergence'),\n",
    "        aes_string('model', 'divergence', color='model')\n",
    "    ) + geom_point(position = position_jitterdodge(dodge.width=0.5, jitter.width=0.5)) +\n",
    "        facet_wrap(vars(divergence_name), nrow=3, scales='free', labeller=as_labeller(facet_labeller)) +\n",
    "        scale_y_log10() +\n",
    "        theme(axis.text.x=element_blank()) +\n",
    "        scale_color_manual(values=source_colors)\n",
    "}\n",
    "\n",
    "compare_model_divergences(df, our_beta)\n",
    "ggsave(output_path('sumrep_divergences.png'), width=8, height=4.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the statistics where the VAEs are performing worst, such as bulkiness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_summaries(prep_summaries(\n",
    "    function(path) getBulkinessDistribution(prep_sumrep(path), column='junction_aa'),\n",
    "    'bulkiness'), \n",
    "'bulkiness')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And aromaticity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_summaries(prep_summaries(\n",
    "    function(path) getAromaticityDistribution(prep_sumrep(path), column='junction_aa'),\n",
    "    'aromaticity'), \n",
    "'aromaticity', binwidth=0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Now let's look at a more sophisticated way of evaluating sequences, namely Ppost. \n",
    "If a synthetically generated sequence doesn't look like a real VDJ recombination, then Ppost will be low."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_ppost = function(path) read.csv(path)$Ppost\n",
    "\n",
    "test_ppost_csvs = \n",
    "    lapply(test_samples, \n",
    "           function(sample) paste0(train_dir, sample, '.for-test.head/ppost.csv'))\n",
    "\n",
    "summaries = prep_summaries_general(\n",
    "    test_ppost_csvs, 'olga-generated.ppost.csv', 'basic/vae-generated.ppost.csv', \n",
    "    'count_match/vae-generated.ppost.csv', get_ppost, 'Ppost')\n",
    "summaries$log_Ppost = log(summaries$Ppost)\n",
    "\n",
    "plot_summaries(summaries, 'log_Ppost') + coord_cartesian(xlim=c(-50, -10))\n",
    "ggsave(output_path('log_Ppost.png'), width=4.5, height=4.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My interpretation of this plot is as follows.\n",
    "\n",
    "The distribution of Ppost for the VAE-generated sequences is comparable to that for the real data. \n",
    "This means that even the very simple model (basic) is learning enough about germline-encoded amino acids to look like real recombinations according to OLGA.\n",
    "We can also see that the VAE is generating a diverse collection of sequences (see the pairwise distance plot) and matching the germline gene usage distribution, so we aren't just generating the same high-probability sequences again and again.\n",
    "\n",
    "What does Pvae look like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_pvae = function(path) read.csv(path)$log_p_x\n",
    "\n",
    "test_pvae_csvs = \n",
    "    lapply(test_samples, \n",
    "           function(sample) fit_path(paste0('basic/',sample,'.for-test.head/test.pvae.csv')))\n",
    "\n",
    "summaries = prep_summaries_general(\n",
    "    test_pvae_csvs, 'basic/olga-generated.pvae.csv', 'basic/vae-generated.pvae.csv', \n",
    "    'count_match/vae-generated.pvae.csv', get_pvae, 'log_Pvae')\n",
    "\n",
    "plot_summaries(summaries, 'log_Pvae') + coord_cartesian(xlim=c(-50, -10))\n",
    "ggsave(output_path('log_Pvae.png'), width=4.5, height=4.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we see a hint that the VAE can tell the difference between OLGA-generated sequences and real sequences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "It's possible that the VAE is just memorizing input sequences and spitting them back out. \n",
    "We can exclude that possibility by looking at out-of-sample likelihoods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = read.csv(extras_path)\n",
    "colnames(df)[colnames(df) == 'test_mean_log_p'] = 'mean log Pvae'\n",
    "colnames(df)[colnames(df) == 'test_median_log_p'] = 'median log Pvae'\n",
    "\n",
    "train_set = lapply(\n",
    "    fromJSON(json_path)$train_paths, \n",
    "    function(path) paste0(tools::file_path_sans_ext(basename(path)),'.for-test.head'))\n",
    "    \n",
    "df$in_train = df$test_set %in% train_set\n",
    "df$beta = as.factor(df$beta)\n",
    "\n",
    "df = df[df$beta == our_beta,]\n",
    "id_vars = c('test_set', 'model', 'in_train')\n",
    "measure_vars = c('mean log Pvae', 'median log Pvae')\n",
    "df = df[df$model != 'olga', c(id_vars, measure_vars)]\n",
    "\n",
    "theme_set(theme_minimal(base_size=18))\n",
    "ggplot(\n",
    "    melt(df, id_vars, measure_vars),\n",
    "    aes(in_train, value, color=model)) + \n",
    "    geom_point(position = position_jitterdodge(dodge.width=0.5, jitter.width=0.2)) +\n",
    "    ylab('log likelihood') + \n",
    "    scale_color_manual(values=source_colors) +\n",
    "    facet_wrap(vars(variable)) +\n",
    "    theme(axis.title.x=element_blank(), legend.justification=c(0.9,0.2), legend.position=c(0.9,0.2)) +\n",
    "    scale_x_discrete(labels=c(\"train\",\"test\"))\n",
    "ggsave(output_path('out_of_sample_likelihoods.png'), width=8, height=4.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The distribution of likelihoods is very similar between train and test, so it appears that these models generalize well."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
