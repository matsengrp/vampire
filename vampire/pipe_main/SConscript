from os.path import join
import glob
import json
import re

import numpy as np

import nestly
import nestly.scons as ns
import SCons.Script as sc

import common
import tcr_vae

sc.Import('env')
localenv = env.Clone()  # noqa


# ### Paths and data sets ###

# This is where we define the paths to the data sets we use.
# There's also the opportunity to add a 'params' dictionary that can modify the base
# dictionary for the nest.

data_path = '/fh/fast/matsen_e/data/'
seshadri_path = join(data_path, 'seshadri/data/Adaptive/clinical_cohort/')

DATA = {
    'dryrun': {
        'paths': ['sample_data/02-0249_TCRB.4000.tsv.bz2']
    },
    'one-seshadri': {
        'paths': [join(seshadri_path, '09-0306_TCRB.tsv')]
    },
    'one-seshadri-tb': {
        'paths': [join(seshadri_path, 'TB-1052-2M_TCRB.tsv')]
    },
    'two-seshadri-tb': {
        'paths': [join(seshadri_path, 'TB-1052-2M_TCRB.tsv'),
                  join(seshadri_path, 'TB-1112_TCRB.tsv')]
    },
    'four-seshadri-tb': {
        'paths': [join(seshadri_path, 'TB-1052-2M_TCRB.tsv'),
                  join(seshadri_path, 'TB-1112_TCRB.tsv'),
                  join(seshadri_path, 'TB-1117_TCRB.tsv'),
                  join(seshadri_path, 'TB-1126_TCRB.tsv')]
    },
    'seshadri': {
        'paths': [join(seshadri_path, '02-0249_TCRB.tsv'),
                  join(seshadri_path, '09-0306_TCRB.tsv')]
    },
    'healthy-seshadri': {
        'paths': glob.glob(join(seshadri_path, '[01]*TCRB.tsv'))
    },
    'tb-seshadri': {
        'paths': glob.glob(join(seshadri_path, 'TB*TCRB.tsv'))
    },
    '10-healthy-seshadri': {
        'paths': glob.glob(join(seshadri_path, '[01]*TCRB.tsv'))[:10]
    },
    'merged-healthy-seshadri': {
        'paths': ['/home/matsen/re/vampire/vampire/_ignore/all-seshadri-01-TCRB.tsv'],
        'base': {
            # Only use a random half of this data set.
            'val_frac': 0.5
        }
    }
}


# ### Command-line-flag related ###

def check_mode():
    if localenv['mode'] not in ['mini', 'default']:
        raise Exception(f"Unknown mode '{localenv['mode']}'")


def apply_mode(l):
    """
    Default mode runs everything, and mini mode just runs a single element from the list.
    """
    check_mode()
    if localenv['mode'] == 'mini':
        return [l[0]]
    else:
        return l


def default_params_by_mode():
    """
    Mini mode doesn't train for long.
    """
    params = tcr_vae.TCRVAE.default_params()

    if localenv['mode'] == 'mini':
        params['pretrains'] = 2
        params['warmup_period'] = 3
        params['epochs'] = 10

    return params


def base_dict():
    """
    The dictionary that will be shared by all the nests.

    nseqs: the number of sequences generated by the various programs, and for
    which we evaluate Pvae for on the real data.

    val_frac: the fraction of sequences to take for validation.

    max_q: the level for truncating q_{lvj} in the thymic Q calculation.
    """

    d = {'nseqs': 500,
         'val_frac': 0.1,
         'max_q': 100,
         }

    if localenv['mode'] == 'mini':
        d['nseqs'] = 100

    data = DATA[localenv['data_label']]
    if 'base' in data:
        for k, v in data['base'].items():
            d[k] = v

    return d


def cluster_execution_string(command, prefix_position=1):
    """
    Apply this to your scons command string* to get it to execute on the
    cluster.

    *The command string but where $SOURCES is replaced by {sources} and
    $TARGETS is replaced by {targets}.

    prefix_position: from where in the command we should get the name of
    the script. 0 for scripts and 1 for subcommands.
    """
    script_prefix = common.strip_extn(command.split()[prefix_position])
    return (
        f"python3 execute.py --clusters='{localenv['clusters']}' --script-prefix={script_prefix} "
        f"'$SOURCES' '$TARGETS' '{command}'"
    )


# ### Misc ###

def numerical_nest_add(nest_name, number_list):
    """
    Add an nest for a list of non-negative numbers, with nice zero-padded
    directory names.
    """
    nest.add(nest_name, apply_mode(number_list), label_func=common.zero_pad_list_func(number_list))


# ### Nests and targets ###

nest = ns.SConsWrap(nestly.Nest(base_dict=base_dict()), alias_environment=localenv)

# Nest: the data set choice, named via data name prepended with `_output_`.
nest.add('data_label', [localenv['data_label']], label_func=lambda p: '_output_' + p)

# The test_set_agg allows us to process the test sets once in the things that don't depend on the VAE.
nest.add_aggregate('test_set_agg', list)
# The test_set_info_agg gathers information about the processed test sets so we can get at them later.
nest.add_aggregate('test_set_info_agg', dict)
# The summarized_agg gathers everything we want to summarize and then stack at the end.
nest.add_aggregate('summarized_agg', list)
summarized_agg_names = []
nest.add_aggregate('loss_regression_agg', list)


@nest.add_target_with_env(localenv)
def sconscript(env, outdir, c):
    """
    Copy SConscript file.
    """
    return env.Command(
        join(outdir, 'SConscript'),
        'SConscript',
        'cp $SOURCE $TARGET')[0]


@nest.add_target_with_env(localenv)
def git_sha(env, outdir, c):
    """
    Echo git sha to file.
    """
    return env.Command(
        join(outdir, 'git-sha.txt'),
        [],
        "git log --pretty=format:'%H' -n 1 > $TARGET")[0]


# Nest: initial processing of the test sets.
nest.add('test_data', DATA[localenv['test_label']]['paths'], label_func=common.strip_dirpath_extn)


@nest.add_target_with_env(localenv)
def preprocess_test(env, outdir, c):
    """
    Run the preprocess_adaptive.py script on the test data.
    """
    in_path = c['test_data']
    return env.Command(
        join(outdir, common.strip_dirpath_extn(in_path) + '.for-test.csv'),
        in_path,
        'python3 preprocess_adaptive.py $SOURCE $TARGET')[0]


@nest.add_target_with_env(localenv)
def test_head(env, outdir, c):
    test_head_path = join(outdir, common.strip_dirpath_extn(c['preprocess_test'])+f".{c['nseqs']}.csv")
    # Remove a pesky and meaningless leading `./` that was making trouble later.
    c['test_set_agg'].append(re.sub('^\./', '', test_head_path))
    return env.Command(
        test_head_path,
        c['preprocess_test'],
        f"cut -f 2-4 -d, $SOURCE | head -n {c['nseqs']+1} > $TARGET")[0]


@nest.add_target_with_env(localenv)
def test_pgen(env, outdir, c):
    test_pgen_path = common.strip_extn(c['test_head'])+'.pgen.tsv'
    c['test_set_info_agg'][(str(c['test_head']), 'test_pgen')] = test_pgen_path
    return env.Command(
        test_pgen_path,
        c['test_head'],
        cluster_execution_string('adaptive-pgen.sh {sources} {targets}', 0))[0]


nest.pop('test_data')


# Nest: the sample, named by sample name.
nest.add('sample', apply_mode(DATA[localenv['data_label']]['paths']), label_func=common.strip_dirpath_extn)
summarized_agg_names.append('sample')


@nest.add_target_with_env(localenv)
def preprocess(env, outdir, c):
    """
    Run the preprocess_adaptive.py script on the training/validation data.
    """
    in_path = c['sample']
    return env.Command(
        join(outdir, common.strip_dirpath_extn(in_path) + '.processed.csv'),
        in_path,
        'python3 preprocess_adaptive.py $SOURCE $TARGET')[0]


# Nest: validation fraction.
# numerical_nest_add('val_frac', [0.99, 0.9, 0.75, 0.5, 0.01])
# summarized_agg_names.append('val_frac')


@nest.add_target_with_env(localenv, 'split')
@ns.name_targets
def split(env, outdir, c):
    """
    Split the sample into training and validation. Note that this is the
    training-validation split even though the command-line flag says
    `test-size`.
    """
    in_path = c['preprocess']
    return 'training', 'validation', env.Command([
        join(outdir, common.strip_dirpath_extn(in_path) + '.training.csv'),
        join(outdir, common.strip_dirpath_extn(in_path) + '.validation.csv')],
        in_path,
        f"python3 util.py split --test-size {c['val_frac']} $SOURCE $TARGETS")


@nest.add_target_with_env(localenv)
def training_pgen(env, outdir, c):
    """
    Get Pgen for the training data.
    """
    return env.Command(
        common.strip_extn(c['split']['training'])+'.pgen.tsv',
        c['split']['training'],
        cluster_execution_string('adaptive-pgen.sh {sources} {targets}', 0))[0]


@nest.add_target_with_env(localenv)
def training_pgen_head(env, outdir, c):
    return env.Command(
        common.strip_extn(c['training_pgen'])+f".{c['nseqs']}.csv",
        c['training_pgen'],
        f"head -n {c['nseqs']+1} $SOURCE > $TARGET")[0]


@nest.add_target_with_env(localenv)
def validation_head(env, outdir, c):
    return env.Command(
        common.strip_extn(c['split']['validation'])+f".{c['nseqs']}.csv",
        c['split']['validation'],
        f"head -n {c['nseqs']+1} $SOURCE > $TARGET")[0]


@nest.add_target_with_env(localenv)
def q_csv(env, outdir, c):
    """
    Calculate values for the thymic Q.
    """
    return env.Command(
        common.strip_extn(c['training_pgen'])+'.q.tsv',
        c['training_pgen'],
        f"python3 thymic_Q.py q --max-q {c['max_q']} data/thymic-Q/model-lvj-frequency.csv.bz2 $SOURCE $TARGET")[0]


@nest.add_target_with_env(localenv)
def training_ppost(env, outdir, c):
    return env.Command(
        common.strip_extn(c['training_pgen_head'])+'.ppost.csv',
        [c['q_csv'], c['training_pgen_head']],
        'python3 thymic_Q.py ppost $SOURCES $TARGET')[0]


@nest.add_target_with_env(localenv)
def validation_pgen(env, outdir, c):
    return env.Command(
        join(outdir, common.strip_dirpath_extn(c['validation_head'])+'.pgen.csv'),
        c['validation_head'],
        cluster_execution_string('adaptive-pgen.sh {sources} {targets}', 0))[0]


@nest.add_target_with_env(localenv)
def validation_ppost(env, outdir, c):
    return env.Command(
        common.strip_extn(c['validation_pgen'])+'.ppost.csv',
        [c['q_csv'], c['validation_pgen']],
        'python3 thymic_Q.py ppost $SOURCES $TARGET')[0]


# Nest: the dimension of the latent space.
# numerical_nest_add('warmup_period', [5*i for i in range(0,6)])
# summarized_agg_names.append('warmup_period')

# Nest: the dimension of the latent space.
# numerical_nest_add('latent_dim', [30, 35, 40])
# summarized_agg_names.append('latent_dim')

# Nest: the number of dense nodes.
# numerical_nest_add('dense_nodes', [50, 75, 100, 125, 150])
# summarized_agg_names.append('dense_nodes')

# Nest: the amino acid embedding dimension.
# numerical_nest_add('aa_embedding_dim', [10, 15, 20, 21])
# summarized_agg_names.append('aa_embedding_dim')

# Nest: the V gene embedding dimension.
# numerical_nest_add('v_gene_embedding_dim', [20, 30, 40])
# summarized_agg_names.append('v_gene_embedding_dim')

# Nest: the strength of the KL component of the VAE loss.
numerical_nest_add('beta', np.linspace(0.5, 1, 5))
summarized_agg_names.append('beta')

# Nest: monitor for EarlyStopping.
# nest.add('stopping_monitor', ['loss', 'val_loss'])
# summarized_agg_names.append('stopping_monitor')

# Nest: EarlyStopping patience.
# numerical_nest_add('patience', [5*x for x in range(7)])
# summarized_agg_names.append('patience')


@nest.add_target_with_env(localenv)
def olga_generated_tsv(env, outdir, c):
    """
    Generate sequences using OLGA + thymic Q.
    """
    return env.Command(
        join(outdir, 'olga-generated.tsv'),
        c['q_csv'],
        f"python3 thymic_Q.py sample --max-q {c['max_q']} --proposal-size {10*c['nseqs']} "
        f"--max-iter 10000 {c['nseqs']} $SOURCE $TARGET")[0]


@nest.add_target_with_env(localenv)
def olga_generated(env, outdir, c):
    """
    Convert OLGA TSV to an Adaptive CSV.
    """
    return env.Command(
        join(outdir, 'olga-generated.csv'),
        c['olga_generated_tsv'],
        'python3 gene_name_conversion.py olga2adaptive $SOURCE $TARGET')[0]


# Nest: the model.
# This needs to appear in the innermost nest so that we can pop it and then do some OLGA work.
# In order to keep things happy when merging with OLGA results, don't comment
# this out if you are only interested in one model. Instead, make a
# single-model nest.
# nest.add('model', apply_mode([common.strip_dirpath_extn(m) for m in glob.glob('../models/*.py')]))
nest.add('model', ['basic', 'count_match', 'germline_decoder'])
summarized_agg_names.append('model')


@nest.add_target_with_env(localenv)
def model_params(env, outdir, c):
    """
    Write out a file with parameters from which we can build our VAE.
    """

    # Copy over any relevant parameters from c into the params dictionary.
    params = default_params_by_mode()
    for k, v in c.items():
        if k in params:
            params[k] = v

    return env.Command(
        join(outdir, 'model_params.json'),
        [],
        f"echo '{json.dumps(params)}' > $TARGET")[0]


@nest.add_target_with_env(localenv, 'trained')
@ns.name_targets
def trained(env, outdir, c):
    return 'weights', 'diagnostics', env.Command(
        [join(outdir, 'best_weights.h5'), join(outdir, 'diagnostics.csv')],
        [c['model_params'], c['split']['training']],
        cluster_execution_string('tcr-vae train {sources} {targets}'))


@nest.add_target_with_env(localenv)
def loss(env, outdir, c):
    loss = join(outdir, 'loss.csv')
    return env.Command(
        loss,
        [c['model_params'], c['trained']['weights'], c['split']['training'],
            c['split']['validation']],
        cluster_execution_string('tcr-vae loss {sources} {targets}'))[0]


@nest.add_target_with_env(localenv)
def training_pvae(env, outdir, c):
    pvae_call = f"tcr-vae pvae --limit-input-to {c['nseqs']}"
    return env.Command(
        join(outdir, common.strip_dirpath_extn(c['split']['training'])+f".{c['nseqs']}.pvae.csv"),
        [c['model_params'], c['trained']['weights'], c['split']['training']],
        cluster_execution_string(pvae_call + ' {sources} {targets}'))[0]


@nest.add_target_with_env(localenv)
def validation_pvae(env, outdir, c):
    return env.Command(
        join(outdir, common.strip_dirpath_extn(c['validation_head'])+'.pvae.csv'),
        [c['model_params'], c['trained']['weights'], c['validation_head']],
        cluster_execution_string('tcr-vae pvae {sources} {targets}'))[0]


@nest.add_target_with_env(localenv)
def vae_generated(env, outdir, c):
    return env.Command(
        join(outdir, 'generated.csv'),
        [c['model_params'], c['trained']['weights']],
        f"tcr-vae generate --nseqs {c['nseqs']} $SOURCES $TARGET")[0]


@nest.add_target_with_env(localenv)
def vae_generated_pgen(env, outdir, c):
    return env.Command(
        common.strip_extn(c['vae_generated'])+'.pgen.tsv',
        c['vae_generated'],
        cluster_execution_string('adaptive-pgen.sh {sources} {targets}', 0))[0]


@nest.add_target_with_env(localenv)
def vae_generated_ppost(env, outdir, c):
    return env.Command(
        common.strip_extn(c['vae_generated'])+'.ppost.csv',
        [c['q_csv'], c['vae_generated_pgen']],
        'python3 thymic_Q.py ppost $SOURCES $TARGET')[0]


@nest.add_target_with_env(localenv)
def olga_generated_pvae(env, outdir, c):
    return env.Command(
        join(outdir, common.strip_dirpath_extn(c['olga_generated'])+'.pvae.csv'),
        [c['model_params'], c['trained']['weights'], c['olga_generated']],
        cluster_execution_string('tcr-vae pvae {sources} {targets}'))[0]


# Nest: evaluation on the test sets.
nest.add('test_set', lambda c: c['test_set_agg'], label_func=common.strip_dirpath_extn)
summarized_agg_names.append('test_set')


# These next two things are handy for outputting where we are in the nest.
idx_name = ';'.join(summarized_agg_names)


def get_idx(c):
    """
    Return a semicolon-separated list of where we are in the nest.
    """
    return ';'.join([str(c[k]) for k in summarized_agg_names])


# @nest.add_target_with_env(localenv)
# def test_per_sequence_loss(env, outdir, c):
#     return env.Command(
#         join(outdir, common.strip_dirpath_extn(c['test_set'])+'.per-seq-loss.csv'),
#         [c['model_params'], c['trained'], c['test_set']],
#         'tcr-vae per-seq-loss $SOURCES $TARGET')[0]


@nest.add_target_with_env(localenv)
def test_pvae(env, outdir, c):
    return env.Command(
        join(outdir, common.strip_dirpath_extn(c['test_set'])+'.pvae.csv'),
        [c['model_params'], c['trained']['weights'], c['test_set']],
        cluster_execution_string('tcr-vae pvae {sources} {targets}'))[0]


@nest.add_target_with_env(localenv)
def vae_sumrep_divergences(env, outdir, c):
    return env.Command(
        common.strip_extn(c['vae_generated'])+'.'+common.strip_dirpath_extn(c['test_set'])+'.sumdiv.csv',
        [c['test_set'], c['vae_generated']],
        'R/rep_divergences.R $SOURCES $TARGET')[0]


# @nest.add_target_with_env(localenv)
# def regress_loss(env, outdir, c):
#     loss_regression = join(outdir, 'loss_regression.csv'),
#     c['loss_regression_agg'].append(loss_regression)
#     return env.Command(
#         loss_regression,
#         [c['test_pvae'], c['test_per_sequence_loss']],
#         f'R/regress_loss.R --idx "{get_idx(c)}" --idx-name "{idx_name}" $SOURCES $TARGET')[0]


# The next target doesn't need to quite so deep in the hierarchy: we could have
# another loop over tests just at the sample level. But this is simpler and
# ppost is cheap to compute.

@nest.add_target_with_env(localenv)
def test_ppost(env, outdir, c):
    c['test_pgen'] = c['test_set_info_agg'][(c['test_set'], 'test_pgen')]
    return env.Command(
        join(outdir, 'ppost.csv'),
        [c['q_csv'], c['test_pgen']],
        'python3 thymic_Q.py ppost $SOURCES $TARGET')[0]


@nest.add_target_with_env(localenv)
def auc_ppost(env, outdir, c):
    return env.Command(
        join(outdir, 'ppost_auc.csv'),
        [c['test_ppost'], c['vae_generated_ppost']],
        'R/auc.R $SOURCES $TARGET')[0]


@nest.add_target_with_env(localenv)
def auc_pvae(env, outdir, c):
    return env.Command(
        join(outdir, 'pvae_auc.csv'),
        [c['test_pvae'], c['olga_generated_pvae']],
        'R/auc.R --pvae $SOURCES $TARGET')[0]


@nest.add_target_with_env(localenv)
def summarized(env, outdir, c):
    summarized = join(outdir, 'summarized.csv')
    # Adding things to the summarized_agg aggregate.
    c['summarized_agg'].append(summarized)
    to_pass = ['loss',
               'training_pvae', 'validation_pvae', 'test_pvae',
               'vae_sumrep_divergences', 'auc_ppost', 'auc_pvae']
    colnames = ','.join(to_pass)
    idx = get_idx(c)
    return env.Command(
        summarized,
        [c[k] for k in to_pass],
        f'python3 util.py summarize --out $TARGET --idx "{idx}" --idx-name "{idx_name}" --colnames {colnames} $SOURCES'
    )[0]


# Now we pop out to model, so that we can do some OLGA stuff that doesn't depend on the VAE model.
nest.pop('model')

# Nest: loop back over the test sets so we can calculate things for OLGA.
nest.add('test_set', lambda c: c['test_set_agg'], label_func=common.strip_dirpath_extn)

# Here we re-calculate test_ppost, which is cheap.


@nest.add_target_with_env(localenv)
def test_ppost(env, outdir, c):
    c['test_pgen'] = c['test_set_info_agg'][(c['test_set'], 'test_pgen')]
    return env.Command(
        join(outdir, 'ppost.csv'),
        [c['q_csv'], c['test_pgen']],
        'python3 thymic_Q.py ppost $SOURCES $TARGET')[0]


@nest.add_target_with_env(localenv)
def olga_sumrep_divergences(env, outdir, c):
    return env.Command(
        join(outdir, 'olga.sumdiv.csv'),
        [c['test_set'], c['olga_generated']],
        'R/rep_divergences.R $SOURCES $TARGET')[0]


@nest.add_target_with_env(localenv)
def olga_summarized(env, outdir, c):
    summarized = join(outdir, 'olga-summarized.csv')
    c['summarized_agg'].append(summarized)
    to_pass = ['training_ppost', 'validation_ppost', 'test_ppost', 'olga_sumrep_divergences']
    colnames = ','.join(to_pass)
    # Here we populate the OLGA indices with some things that are not relevant, such as VAE model parameters.
    # This repeats unnecessarily, but it makes downstream plotting easier because we can treat all the models the same.
    c_copy = dict(c)
    c_copy['model'] = 'olga'
    idx = get_idx(c_copy)
    return env.Command(
        summarized,
        [c[k] for k in to_pass],
        f'python3 util.py summarize --out $TARGET --idx "{idx}" --idx-name "{idx_name}" --colnames {colnames} $SOURCES'
    )[0]


# Pop all the way back to the very beginning for a complete summary.
nest.pop(summarized_agg_names[0])


@nest.add_target_with_env(localenv)
def summarized_agg_target(env, outdir, c):
    return env.Command(
        join(outdir, 'summarized.agg.csv'),
        c['summarized_agg'],
        'python3 util.py stackrows --out $TARGET $SOURCES')[0]


# @nest.add_target_with_env(localenv)
# def loss_regression_agg_target(env, outdir, c):
#     return env.Command(
#         join(outdir, 'loss_regression.agg.csv'),
#         c['loss_regression_agg'],
#         'python3 util.py stackrows --out $TARGET $SOURCES')[0]
