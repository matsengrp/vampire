from os.path import join
import glob
import json
import os

import nestly
import nestly.scons as ns
import SCons.Script as sc

import common
import tcr_vae

sc.Import('env')
localenv = env.Clone()  # noqa


# ### Paths and data sets ###

data_path = '/fh/fast/matsen_e/data/'
seshadri_path = join(data_path, 'seshadri/data/Adaptive/clinical_cohort/')

DATA = {
    'dryrun': {
        'paths': ['sample_data/02-0249_TCRB.4000.tsv.bz2']
    },
    'one-seshadri': {
        'paths': [join(seshadri_path, '09-0306_TCRB.tsv')]
    },
    'one-seshadri-tb': {
        'paths': [join(seshadri_path, 'TB-1052-2M_TCRB.tsv')]
    },
    'seshadri': {
        'paths': [join(seshadri_path, '02-0249_TCRB.tsv'),
                  join(seshadri_path, '09-0306_TCRB.tsv')]
    },
    'healthy-seshadri': {
        'paths': glob.glob(join(seshadri_path, '[01]*TCRB.tsv'))
    },
    '10-healthy-seshadri': {
        'paths': glob.glob(join(seshadri_path, '[01]*TCRB.tsv'))[:10]
    },
    'merged-healthy-seshadri': {
        'paths': ['/home/matsen/re/vampire/vampire/_ignore/all-seshadri-01-TCRB.tsv']
    }
}


# ### Command-line-flag related ###

def check_mode():
    if localenv['mode'] not in ['mini', 'default']:
        raise Exception(f"Unknown mode '{localenv['mode']}'")


def apply_mode(l):
    """
    Default mode runs everything, and mini mode just runs a single element from the list.
    """
    check_mode()
    if localenv['mode'] == 'mini':
        return [l[0]]
    else:
        return l


def default_params_by_mode():
    """
    Mini mode doesn't train for long.
    """
    params = tcr_vae.TCRVAE.default_params()

    if localenv['mode'] == 'mini':
        params['epochs'] = 5

    return params


def base_dict():
    """
    The dictionary that will be shared by all the nests.

    nseqs: the number of sequences generated by the various programs, and for
    which we evaluate Pvae for on the real data.

    val_frac: the fraction of sequences to take for validation.
    """

    d = {'nseqs': 500,
         'val_frac': 0.1,
         }

    if localenv['mode'] == 'mini':
        d['nseqs'] = 100

    return d


def cluster_execution_string(command, prefix_position=1):
    """
    Apply this to your scons command string* to get it to execute on the
    cluster.

    *The command string but where $SOURCES is replaced by {sources} and
    $TARGETS is replaced by {targets}.
    """
    # If we have a subcommand structure, prefix_position=1 makes a nice script prefix.
    script_prefix = command.split()[prefix_position]
    return (
        f"python3 execute.py --clusters='{localenv['clusters']}' --script-prefix={script_prefix} "
        f"'$SOURCES' '$TARGETS' '{command}'"
    )


# ### Misc ###

def numerical_nest_add(nest_name, number_list):
    """
    Add an nest for a list of non-negative numbers, with nice zero-padded
    directory names.
    """
    nest.add(nest_name, apply_mode(number_list), label_func=common.zero_pad_list_func(number_list))


# ### Nests and targets ###

nest = ns.SConsWrap(nestly.Nest(base_dict=base_dict()), alias_environment=localenv)

# Nest: the data set choice, named via data name prepended with `_output_`.
nest.add('data_label', [localenv['data_label']], label_func=lambda p: '_output_' + p)

nest.add_aggregate('test_set_agg', list)
nest.add_aggregate('summarized_agg', list)
summarized_agg_names = []
nest.add_aggregate('loss_regression_agg', list)


@nest.add_target_with_env(localenv)
def sconscript(env, outdir, c):
    """
    Copy SConscript file.
    """
    return env.Command(
        join(outdir, 'SConscript'),
        'SConscript',
        'cp $SOURCE $TARGET')[0]


@nest.add_target_with_env(localenv)
def git_sha(env, outdir, c):
    """
    Echo git sha to file.
    """
    return env.Command(
        join(outdir, 'git-sha.txt'),
        [],
        "git log --pretty=format:'%H' -n 1 > $TARGET")[0]


@nest.add_target_with_env(localenv)
def olga_generated_tsv(env, outdir, c):
    """
    Generate sequences using OLGA.
    """
    return env.Command(
        join(outdir, 'olga-generated.tsv'),
        [],
        f"scripts/olga-generate.sh {c['nseqs']} $TARGET")[0]


@nest.add_target_with_env(localenv)
def olga_generated(env, outdir, c):
    """
    Convert OLGA TSV to a adaptive CSV.
    """
    return env.Command(
        join(outdir, 'olga-generated.csv'),
        c['olga_generated_tsv'],
        'python3 gene_name_conversion.py olga2adaptive $SOURCE $TARGET')[0]


@nest.add_target_with_env(localenv)
def olga_generated_sumrep(env, outdir, c):
    return env.Command(
        common.strip_extn(c['olga_generated'])+'.sumrep.csv',
        c['olga_generated'],
        'R/single_rep_summaries.R $SOURCE $TARGET')[0]


# Nest: initial processing of the test sets.
nest.add('test_data', DATA[localenv['test_label']]['paths'], label_func=common.strip_dirpath_extn)


@nest.add_target_with_env(localenv)
def preprocess_test(env, outdir, c):
    """
    Run the preprocess_adaptive.py script on the test data.
    """
    in_path = c['test_data']
    return env.Command(
        join(outdir, common.strip_dirpath_extn(in_path) + '.for-test.csv'),
        in_path,
        'python3 preprocess_adaptive.py $SOURCE $TARGET')[0]


@nest.add_target_with_env(localenv)
def test_head(env, outdir, c):
    test_head_path = join(outdir, common.strip_dirpath_extn(c['preprocess_test'])+f".{c['nseqs']}.csv")
    c['test_set_agg'].append(test_head_path)
    return env.Command(
        test_head_path,
        c['preprocess_test'],
        f"cut -f 2-4 -d, $SOURCE | head -n {c['nseqs']+1} > $TARGET")[0]


@nest.add_target_with_env(localenv)
def test_sumrep(env, outdir, c):
    return env.Command(
        common.strip_extn(c['test_head'])+'.sumrep.csv',
        c['test_head'],
        'R/single_rep_summaries.R $SOURCE $TARGET')[0]


@nest.add_target_with_env(localenv)
def olga_sumrep_divergences(env, outdir, c):
    return env.Command(
        common.strip_extn(c['test_head'])+'-olga.sumdiv.csv',
        [c['test_head'], c['olga_generated']],
        'R/rep_divergences.R $SOURCES $TARGET')[0]


nest.pop('test_data')


# Nest: the sample, named by sample name.
nest.add('sample', apply_mode(DATA[localenv['data_label']]['paths']), label_func=common.strip_dirpath_extn)
summarized_agg_names.append('sample')


@nest.add_target_with_env(localenv)
def preprocess(env, outdir, c):
    """
    Run the preprocess_adaptive.py script on the training/validation data.
    """
    in_path = c['sample']
    return env.Command(
        join(outdir, common.strip_dirpath_extn(in_path) + '.processed.csv'),
        in_path,
        'python3 preprocess_adaptive.py $SOURCE $TARGET')[0]


# # Nest: validation fraction.
# numerical_nest_add('val_frac', [0.99, 0.9, 0.75, 0.5, 0.01])
# summarized_agg_names.append('val_frac')


@nest.add_target_with_env(localenv, 'split')
@ns.name_targets
def split(env, outdir, c):
    """
    Split the sample into training and validation. Note that this is the
    training-validation split even though the command-line flag says
    `test-size`.
    """
    in_path = c['preprocess']
    return 'training', 'validation', env.Command([
        join(outdir, common.strip_dirpath_extn(in_path) + '.training.csv'),
        join(outdir, common.strip_dirpath_extn(in_path) + '.validation.csv')],
        in_path,
        f"python3 util.py split --test-size {c['val_frac']} $SOURCE $TARGETS")


# Nest: the model.
# In order to keep things happy when merging with OLGA results, don't comment
# this out if you are only interested in one model. Instead, make a
# single-model nest.
# nest.add('model', apply_mode([common.strip_dirpath_extn(m) for m in glob.glob('../models/*.py')]))
nest.add('model', ['basic', 'count_match'])
summarized_agg_names.append('model')

# Nest: the dimension of the latent space.
# numerical_nest_add('latent_dim', [30, 35, 40])
numerical_nest_add('latent_dim', [35])
summarized_agg_names.append('latent_dim')

# Nest: the number of dense nodes.
# numerical_nest_add('dense_nodes', [50, 75, 100, 125, 150])
numerical_nest_add('dense_nodes', [10, 25, 50, 100, 150, 200])
summarized_agg_names.append('dense_nodes')

# # Nest: the amino acid embedding dimension.
# numerical_nest_add('aa_embedding_dim', [10, 15, 20, 21])
# summarized_agg_names.append('aa_embedding_dim')

# # Nest: the V gene embedding dimension.
# numerical_nest_add('v_gene_embedding_dim', [20, 30, 40])
# summarized_agg_names.append('v_gene_embedding_dim')

# # Nest: the strength of the KL component of the VAE loss.
# numerical_nest_add('beta', [2.**i for i in range(-4, 4, 2)])
# summarized_agg_names.append('beta')


@nest.add_target_with_env(localenv)
def model_params(env, outdir, c):
    """
    Write out a file with parameters from which we can build our VAE.
    """

    # Copy over any relevant parameters from c into the params dictionary.
    params = default_params_by_mode()
    for k, v in c.items():
        if k in params:
            params[k] = v

    return env.Command(
        join(outdir, 'model_params.json'),
        [],
        f"echo '{json.dumps(params)}' > $TARGET")[0]


@nest.add_target_with_env(localenv, 'trained')
@ns.name_targets
def trained(env, outdir, c):
    return 'weights', 'diagnostics', env.Command(
        [join(outdir, 'best_weights.h5'), join(outdir, 'diagnostics.csv')], [c['model_params'], c['split']['training']],
        cluster_execution_string('tcr-vae train {sources} {targets}'))


@nest.add_target_with_env(localenv)
def vae_generated(env, outdir, c):
    return env.Command(
        join(outdir, 'generated.csv'),
        [c['model_params'], c['trained']['weights']],
        f"tcr-vae generate --nseqs {c['nseqs']} $SOURCES $TARGET")[0]


@nest.add_target_with_env(localenv)
def vae_generated_pgen(env, outdir, c):
    return env.Command(
        common.strip_extn(c['vae_generated'])+'.pgen.csv',
        c['vae_generated'],
        'scripts/olga-pgen.sh $SOURCE $TARGET')[0]


@nest.add_target_with_env(localenv)
def vae_generated_sumrep(env, outdir, c):
    return env.Command(
        common.strip_extn(c['vae_generated'])+'.sumrep.csv',
        c['vae_generated'],
        'R/single_rep_summaries.R $SOURCE $TARGET')[0]


@nest.add_target_with_env(localenv)
def olga_generated_pvae(env, outdir, c):
    return env.Command(
        join(outdir, common.strip_dirpath_extn(c['olga_generated'])+'.pvae.csv'),
        [c['model_params'], c['trained']['weights'], c['olga_generated']],
        cluster_execution_string('tcr-vae pvae {sources} {targets}'))[0]


# Nest: evaluation on the test sets.
nest.add('test_set', lambda c: c['test_set_agg'], label_func=common.strip_dirpath_extn)
summarized_agg_names.append('test_set')


# These next two things are handy for outputting where we are in the nest.
idx_name = ';'.join(summarized_agg_names)


def get_idx(c):
    """
    Return a semicolon-separated list of where we are in the nest.
    """
    return ';'.join([str(c[k]) for k in summarized_agg_names])


@nest.add_target_with_env(localenv)
def loss(env, outdir, c):
    return env.Command(
        join(outdir, 'loss.csv'),
        [c['model_params'], c['trained']['weights'], c['split']['training'],
            c['split']['validation'], c['test_set']],
        'tcr-vae loss $SOURCES $TARGET')[0]


@nest.add_target_with_env(localenv)
def test_per_sequence_loss(env, outdir, c):
    return env.Command(
        join(outdir, common.strip_dirpath_extn(c['test_set'])+'.per-seq-loss.csv'),
        [c['model_params'], c['trained']['weights'], c['test_set']],
        'tcr-vae per-seq-loss $SOURCES $TARGET')[0]


@nest.add_target_with_env(localenv)
def test_pvae(env, outdir, c):
    return env.Command(
        join(outdir, common.strip_dirpath_extn(c['test_set'])+'.pvae.csv'),
        [c['model_params'], c['trained']['weights'], c['test_set']],
        cluster_execution_string('tcr-vae pvae {sources} {targets}'))[0]


@nest.add_target_with_env(localenv)
def vae_sumrep_divergences(env, outdir, c):
    return env.Command(
        common.strip_extn(c['vae_generated'])+'-test.sumdiv.csv',
        [c['test_set'], c['vae_generated']],
        'R/rep_divergences.R $SOURCES $TARGET')[0]


# @nest.add_target_with_env(localenv)
# def regress_loss(env, outdir, c):
#     loss_regression = join(outdir, 'loss_regression.csv'),
#     c['loss_regression_agg'].append(loss_regression)
#     return env.Command(
#         loss_regression,
#         [c['test_pvae'], c['test_per_sequence_loss']],
#         f'R/regress_loss.R --idx "{get_idx(c)}" --idx-name "{idx_name}" $SOURCES $TARGET')[0]


# TODO To move this into the first test nest we need to pack more information
# into our test agg.
@nest.add_target_with_env(localenv)
def test_pgen(env, outdir, c):
    return env.Command(
        common.strip_extn(c['test_set'])+'.pgen.csv',
        c['test_set'],
        'scripts/olga-pgen.sh $SOURCE $TARGET')[0]


@nest.add_target_with_env(localenv)
def auc_pgen(env, outdir, c):
    # Below is not a typo:  we are using the location of test_pvae as a place to put our Pgen AUC.
    return env.Command(
        join(os.path.dirname(str(c['test_pvae'])), 'pgen_auc.csv'),
        [c['test_pgen'], c['vae_generated_pgen']],
        'R/auc.R $SOURCES $TARGET')[0]


@nest.add_target_with_env(localenv)
def auc_pvae(env, outdir, c):
    return env.Command(
        join(os.path.dirname(str(c['test_pvae'])), 'pvae_auc.csv'),
        [c['test_pvae'], c['olga_generated_pvae']],
        'R/auc.R --pvae $SOURCES $TARGET')[0]


@nest.add_target_with_env(localenv)
def summarized(env, outdir, c):
    summarized = join(outdir, 'summarized.csv')
    # Adding things to the summarized_agg aggregate.
    c['summarized_agg'].append(summarized)
    to_pass = ['loss', 'test_pvae', 'test_pgen', 'vae_generated_pgen', 'vae_generated_sumrep', 'vae_sumrep_divergences',
               'auc_pgen', 'auc_pvae']
    colnames = ','.join(to_pass)
    idx = get_idx(c)
    return env.Command(
        summarized,
        [c[k] for k in to_pass],
        f'python3 util.py summarize --out $TARGET --idx "{idx}" --idx-name "{idx_name}" --colnames {colnames} $SOURCES'
    )[0]


# TODO To make this work we need to pack more information into our test agg.
# # Pop all the way down to sample, so we can summarize OLGA.
# for nest_name in reversed(summarized_agg_names[1:]):
#     nest.pop(nest_name)
#
#
# # We need to have the OLGA summary here so that we have summarized_agg_names populated.
# @nest.add_target_with_env(localenv)
# def olga_summarized(env, outdir, c):
#     summarized = join(outdir, 'olga-summarized.csv')
#     c['summarized_agg'].append(summarized)
#     to_pass = ['olga_sumrep_divergences']
#     colnames = ','.join(to_pass)
#     # OLGA doesn't have any free parameters, so it only gets the one identifier.
#     pre_idx = [c[summarized_agg_names[0]], 'olga'] + ['']*(len(summarized_agg_names)-2)
#     idx = ';'.join(pre_idx)
#     return env.Command(
#         summarized,
#         [c[k] for k in to_pass],
#        f'python3 util.py summarize --out $TARGET --idx "{idx}" --idx-name "{idx_name}" --colnames {colnames} $SOURCES'
#     )[0]


nest.pop(summarized_agg_names[0])


@nest.add_target_with_env(localenv)
def summarized_agg_target(env, outdir, c):
    return env.Command(
        join(outdir, 'summarized.agg.csv'),
        c['summarized_agg'],
        'python3 util.py stackrows --out $TARGET $SOURCES')[0]


# @nest.add_target_with_env(localenv)
# def loss_regression_agg_target(env, outdir, c):
#     return env.Command(
#         join(outdir, 'loss_regression.agg.csv'),
#         c['loss_regression_agg'],
#         'python3 util.py stackrows --out $TARGET $SOURCES')[0]
